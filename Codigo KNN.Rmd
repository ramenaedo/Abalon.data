---
title: "R Notebook"
output: html_notebook
---



```{r}
library("dplyr")
library("class")
library("ggplot2")
library("caret")
library("kknn")
library("kableExtra")
library("caTools")
library("pROC")
```


```{r}
download.file(url = "https://raw.githubusercontent.com/ramenaedo/Abalon.data/main/abalone.data", destfile = "abalon.data")
datos<-read_csv("abalon.data")
#path = "D:/Documentos/2022-2/Aplica/Proyecto Final/abalone.data"
#datos = read.table(file = path, header = FALSE, sep = ",")
colnames(datos) <- c("Sex","Lenght","Diameter","Height","Whole weight","Shucked weight","Viscera weight","Shell weight","Rings")
datos$Rings <- as.factor(datos$Rings)
attach(datos)
View(datos)
datos <- data.frame(datos)
summary(Rings);summary(datos)
datos

```

```{r}
Male <- ifelse(Sex == "M", 1, 0)
Female <- ifelse(Sex == "F", 1, 0)
Infant <- ifelse(Sex == "I", 1, 0)
datos <- datos[,-c(1)]
datos <- cbind(Male,Female,Infant,datos[,])
datos
```
#Analizaremos primero la precisión de KNN para la variable respuesta sin modificar
```{r}
conjuntos <- createFolds(Rings, k = 10)
K = c()
for (kk in 1:30)
  {
  vcknn <- lapply(conjuntos,function(x)
  {
   conjunto_entrenamiento <- data.frame(datos[-x,])
   conjunto_prueba <- data.frame(datos[x,])
   prediccion <- knn(train = conjunto_entrenamiento[,-11], 
                     test = conjunto_prueba[,-11], 
                     cl = conjunto_entrenamiento[,11], 
                     k = kk)
   tabla_confusion <- table(conjunto_prueba[,11], prediccion)
   return(sum(diag(tabla_confusion))/sum(tabla_confusion))
  })
  K[kk] = mean(as.numeric(vcknn))
}
order(K,decreasing = TRUE)[1:10]
print(K[order(K,decreasing = TRUE)[1:10]])
plot( x = 1:30, y = K,  main = "Precisión k vecinos cercanos", xlab = "k", ylab = "Precisión", col = "blue", type = "l", pch = 4, xlim = c(0,30), ylim = c(0,1))

```
#Se observa que deja mucho que desear los resultados obtenidos


#Ahora definamos una nueva variable de decisión como joven(<=11)/viejo(>11)
```{r}
datosbin <- datos
datosbin$Rings <- as.numeric(datosbin$Rings)
datosbin$Rings <- ifelse(datosbin$Rings < 11, 0, 1)
datosbin$Rings <- as.factor(datosbin$Rings)
attach(datosbin)
datosbin
```

#Veamos como se comporta datosbin con knn, si quiere correrlo mas rapido cambie el k max (300) por algo mucho menor
(Dentro del codigo se usa 100 para saber como se ve, sin embargo se utilizo 300)
```{r}

conjuntos <- createFolds(datosbin$Rings, k = 10)
K = c()

for (kk in 1:100)
  {
  vcknn <- lapply(conjuntos,function(x)
  {
   conjunto_entrenamiento <- data.frame(datosbin[-x,])
   conjunto_prueba <- data.frame(datosbin[x,])
   prediccion <- knn(train = conjunto_entrenamiento[,-11], 
                     test = conjunto_prueba[,-11], 
                     cl = conjunto_entrenamiento[,11], 
                     k = kk)
   tabla_confusion <- table(conjunto_prueba[,11], prediccion)
   return(sum(diag(tabla_confusion))/sum(tabla_confusion))
  })
  K[kk] = mean(as.numeric(vcknn))
}
order(K,decreasing = TRUE)[1:30]
print(K[order(K,decreasing = TRUE)[1:30]])
plot( x = 1:300, y = K,  main = "Precisión k vecinos cercanos", xlab = "k", ylab = "Precisión", col = "blue", type = "l", pch = 4, xlim = c(0,300), ylim = c(0,1))
```

#Otra forma de ver k-fold cross validation con la libreria caret
```{r}

trControl <- trainControl(method  = "cv",
                          number  = 5)
fit <- train(Rings ~ .,
             method     = "knn",
             tuneGrid   = expand.grid(k = 1:10),
             trControl  = trControl,
             metric     = "Accuracy",
             data       = datosbin)
fit

```


#Ahora veamos la curva Roc y el AUC de KNN para datosbin
```{r}
train_index <- createDataPartition(datosbin$Rings, p = 0.8, list = FALSE, times = 1)
train = datosbin[train_index,]
test = datosbin[-train_index,]
modelo <- class::knn(train[,-11], test[,-11], cl = train[,11], k=13, prob=TRUE)
prob <- attr(modelo, "prob")
roc <- roc( test $ Rings ~ prob , plot = TRUE, print.auc = TRUE )
print(roc$auc)

```

```{r}

aucs = c()

for (kk in 1:100)
{
  train_index <- createDataPartition(datosbin$Rings, p = 0.8, list = FALSE, times = 1)
  train = datosbin[train_index,]
  test = datosbin[-train_index,]
  modelo <- class::knn(train[,-11], test[,-11], cl = train[,11], k=13, prob=TRUE)
  prob <- attr(modelo, "prob")
  roc <- roc( test $ Rings ~ prob , plot = FALSE, print.auc = FALSE )
  aucs[kk] = roc$auc
}
plot( x = 1:100, y = aucs,  main = "Valor auc para 100 iteraciones", xlab = "iteración", ylab = "Valor auc", col = "black", type = "p", pch = 1, xlim = c(0,100), ylim = c(0,1))
print(mean(aucs))
```
#Se observa que es KNN es un clasificador que obtiene resultados regulares para el conjunto datosbin, pues AUC < 0.75 y > 0.6
